download: [https://arxiv.org/pdf/1506.01497]

title: 

Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

authors: Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun

[TOC]

---

### Abstract

RPN: Region Proposal Network + Fast R-CNN

RPN as a 'attention' tell the unified network where to look.

for VGG-16 model, 5fps with only 300 proposals per image.

### 1. Introduction

proposals test-time bottleneck

the conv feature maps used by region-based detectors can also be used for generating region proposals

RPN is FCN(fully convolutional network)

"anchor" boxes as references at multiple scales and aspect ratios.


unify RPN with Fast R-CNN:  alternate between ft for the region proposal task and then ft for object detection. conv features are shared between both tasks.

RPNs can also be trained jointly leading to less training time.

RPN completely learn to propose regions from data.



### 2. Related Work


#### Object Proposals


Grouping super-pixels: eg. Selective search , CPMC, MCG
Sliding windows: objectness in windows, EdgeBoxes

Object proposal methods were adopted as external modules independent of the detectors.

#### Deep Networks for Object Detection


OverFeat: fc (predict the box coordinates for the localization task that assumes a single object) -> conv (detecting multiple class-specific objects)

MultiBox: region proposals from a network whose last fc layer simultaneously predicts multiple class-agnostic boxes

### 3. Faster R-CNN

composed of 2 modules:

1. deep fully conv network that propose regions
2. Fast R-CNN detector

![CrI1T1.png](https://s1.ax1x.com/2018/05/14/CrI1T1.png)


它是一个single, unified network.


#### 3.1 Region Proposal Networks

RPN: 
输入: an any size full image.
输出: a set of rectangular object proposals. each with an objectness score.

objectness 意味着是 object classes vs. background.


ZF-Net which has 5 shareable conv layers and VGG-16 which has 13 shareable conv layers.

slide a small network over the conv feature map output by the last shared conv layer.

the small network input nxn(**n=3 here**)spatial window of the f.m (feature map).

每一个滑动窗口都被映射为一个低维的feature (256-d for ZF and 512-d for VGG), with ReLU following.

这个特征被送入two sibling fc layers: 一个是box-regression layer(reg) and a box-classification layer(cls).

##### 3.1.1 Anchors


在每个滑动窗口位置, 我们同时预测多个region proposals(最大数量是k).

因此reg有4k个输出, 编码了k个boxes.

cls有2k个输出, 分别是有物体和没有物体(background)的概率 (也可以输出k个，用logistic regression, 本文为了简单, 直接使用了2-class的softmax layer).

k个proposals相对于k个reference boxes. 我们叫它们为anchors.

一个anchor居中于sliding window， 代表一个特定的scale和aspect ratio.

默认, scale有3个, aspect ratio有3种，因此k=3x3=9.

对一个有WxH(~2,400)大小的feature map, 一共可以产生WxHxk个anchors.

**Translation-Invariant Anchors**

If one translates an object in an image, the proposal should translate and the same function should be able to predict the proposal in either localtion.


**Multi-Scale Anchors as Regression References**

##### 3.1.2 Loss Function



每一个anchor都有一个label(object or not).

positive label:

2 kinds of anchors

(i) the anchor/anchors with the highest IoU overlap with a gt box;
(ii) an anchor that has an IoU overlap higher than 0.7 with any gt box.

negative label:

to a non-positive anchor if its IoU ratio is lower than 0.3 for all gt boxes.

既不是pos也不是neg的anchors对training objective没有贡献.

loss function for an image:

![CrT8xO.png](https://s1.ax1x.com/2018/05/14/CrT8xO.png)

i是一个mini-batch中一个anchor的下标,p_i是anchor i 属于一个object的预测概率.


p*_i是gt label: 如果anchor i是pos则为1, 如果是neg则为0.

N_cls: mini-batch size = 256
N_reg: normalized by the number of anchor locations ~ 2,400.

默认, λ=10.

k regressors not share weights.

##### 3.1.3 Training RPNs

...

#### 3.2 Sharing Features for RPN and Fast-RCNN


Both RPN and Fast R-CNN trained independently, will modify their convolutional layers in different ways.

3 ways for training networks with features shared:

1. Alternate training:
首先训练RPN, 再用RPN产生的proposals去训练Fast R-CNN, 被Fast R-CNN训练所更新的RPN作为初始值,再去迭代产生proposals, 这是本文所有实验所用的方式.

2. Approximate joint training:
忽略了proposal boxes' coordinates的偏微分影响, 它也是网络的响应的一部分。

3. Non-approximate joint training:

'RoI warping'

**4-step alternating training**


step 1:

train RPN(with an ImageNet pre-trained model and ft end-to-end for the region proposal task)


step 2:

train a separate detection network by Fast R-CNN using the proposals generated by the step 1 RPN;

 step 3:

 we use the detector network to initialize RPN training, but we fix the shared conv layers and only ft the layers unique to RPN.

 step 4:

 keeping the shared conv layer fixed, we ft the unique layers of Fast R-CNN.

 #### 3.3 Implementation Details

 ...

 

